{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/miniconda3/envs/pytorch5070/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import os\n",
    "import random\n",
    "import config\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "sys.path.append('../util')\n",
    "from DatasetAugmentation import *\n",
    "\n",
    "# First download the FUSEG dataset:\n",
    "# https://github.com/uwm-bigdata/wound-segmentation/tree/master/data/Foot%20Ulcer%20Segmentation%20Challenge\n",
    "\n",
    "\n",
    "#Enter the root name of the original dataset\n",
    "original_dataset_path = '/mnt/TUDAO/0Datasets/fuseg/original'\n",
    "output_base           = '/mnt/TUDAO/0Datasets/fuseg/augmented-v3-512'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ecb6b",
   "metadata": {},
   "source": [
    "### Removing images without masks from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def move_black_masks(\n",
    "    masks_path, \n",
    "    imgs_path, \n",
    "    output_path, \n",
    "    extensions=(\".png\", \".jpg\", \".jpeg\", \".tif\")\n",
    "):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    black_masks = []\n",
    "\n",
    "    for root, _, files in os.walk(masks_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                mask_path = os.path.join(root, file)\n",
    "                img = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "                if img is None:\n",
    "                    print(f\"[WARNING] Unable to read {mask_path}\")\n",
    "                    continue\n",
    "\n",
    "                # Convert to grayscale if you have multiple channels\n",
    "                if len(img.shape) == 3:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Checks if all pixels are 0\n",
    "                if np.all(img == 0):\n",
    "                    base_name, _ = os.path.splitext(file)\n",
    "                    black_masks.append(base_name)\n",
    "\n",
    "                    # Matching image path\n",
    "                    img_path = None\n",
    "                    for ext in extensions:\n",
    "                        attempt = os.path.join(imgs_path, base_name + ext)\n",
    "                        if os.path.exists(attempt):\n",
    "                            img_path = attempt\n",
    "                            break\n",
    "\n",
    "                    # Move mask\n",
    "                    new_name_mask = f\"{base_name}_mask.png\"\n",
    "                    output_mask = os.path.join(output_path, new_name_mask)\n",
    "                    shutil.move(mask_path, output_mask)\n",
    "\n",
    "                    # Move image if exists\n",
    "                    if img_path and os.path.exists(img_path):\n",
    "                        destino_img = os.path.join(output_path, os.path.basename(img_path))\n",
    "                        shutil.move(img_path, destino_img)\n",
    "                    else:\n",
    "                        print(f\"[WARNING] Matching image not found for {file}\")\n",
    "\n",
    "                    print(f\"[OK] Moved: {file} and corresponding image\")\n",
    "\n",
    "    print(f\"\\nTotal black masks moved:{len(black_masks)}\")\n",
    "    return black_masks\n",
    "\n",
    "\n",
    "\n",
    "# Path of the original masks\n",
    "dir_mascaras = f\"{original_dataset_path}/train/labels\"\n",
    "# Original images path\n",
    "dir_imagens = f\"{original_dataset_path}/train/images\"\n",
    "# Destination path where they will be moved\n",
    "dir_destino = f\"{original_dataset_path}/train-fix/\"\n",
    "\n",
    "move_black_masks(dir_mascaras, dir_imagens, dir_destino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56fe3a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Moved: 0417.png and corresponding image\n",
      "[OK] Moved: 0483.png and corresponding image\n",
      "[OK] Moved: 0869.png and corresponding image\n",
      "\n",
      "Total black masks moved:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0417', '0483', '0869']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path of the original masks\n",
    "dir_mascaras = f\"{original_dataset_path}/test/labels\"\n",
    "# Original images path\n",
    "dir_imagens = f\"{original_dataset_path}/test/images\"\n",
    "# Destination path where they will be moved\n",
    "dir_destino = f\"{original_dataset_path}/test-fix/\"\n",
    "\n",
    "move_black_masks(dir_mascaras, dir_imagens, dir_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d19b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Moved: 0128.png and corresponding image\n",
      "[OK] Moved: 0533.png and corresponding image\n",
      "\n",
      "Total black masks moved:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0128', '0533']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path of the original masks\n",
    "dir_mascaras = f\"{original_dataset_path}/validation/labels\"\n",
    "# Original images path\n",
    "dir_imagens = f\"{original_dataset_path}/validation/images\"\n",
    "# Destination path where they will be moved\n",
    "dir_destino = f\"{original_dataset_path}/validation-fix/\"\n",
    "\n",
    "move_black_masks(dir_mascaras, dir_imagens, dir_destino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290a39a",
   "metadata": {},
   "source": [
    "### Moving 100 images from validation to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872e44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_img_dir = os.path.join(original_dataset_path, \"validation\", \"images\")\n",
    "from_lbl_dir = os.path.join(original_dataset_path, \"validation\", \"labels\")\n",
    "to_img_dir = os.path.join(original_dataset_path, \"test\", \"images\")\n",
    "to_lbl_dir = os.path.join(original_dataset_path, \"test\", \"labels\")\n",
    "\n",
    "os.makedirs(to_img_dir, exist_ok=True)\n",
    "os.makedirs(to_lbl_dir, exist_ok=True)\n",
    "\n",
    "images = os.listdir(from_img_dir)\n",
    "selected = random.sample(images, 100)\n",
    "\n",
    "for img in selected:\n",
    "    shutil.move(os.path.join(from_img_dir, img), os.path.join(to_img_dir, img))\n",
    "    shutil.move(os.path.join(from_lbl_dir, img), os.path.join(to_lbl_dir, img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84705ee1",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in the original dataset: 791\n",
      "→ Training: 791\n",
      "→ Validation (of training): 0\n",
      "→ Test (training): 0\n",
      "\n",
      "With N=10, total images generated in training will be: 8701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/miniconda3/envs/pytorch5070/lib/python3.10/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "Copiando valid: 100%|██████████| 100/100 [00:02<00:00, 34.62it/s]\n",
      "Copiando test: 100%|██████████| 300/300 [00:01<00:00, 164.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 100 images copied from the original valid folder.\n",
      "→ 100 images copied from the original test folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enlarging workout images: 100%|██████████| 791/791 [04:50<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final summary:\n",
      "train_images: 8701 files\n",
      "train_labels: 8701 files\n",
      "valid_images: 100 files\n",
      "valid_labels: 100 files\n",
      "test_images: 100 files\n",
      "test_labels: 100 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "#Data augmentation was performed by generating ten augmented images for each image in the training set.\n",
    "N = 10  # number of augmentations\n",
    "num_to_valid = 0    # number of images to move from train to valid\n",
    "num_to_test  = 0    # number of images to move from train to test\n",
    "\n",
    "\n",
    "target_size  = (512, 512)\n",
    "random.seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# Entry and exit paths\n",
    "# -----------------------------\n",
    "orig_train_img_dir  = os.path.join(original_dataset_path, 'train/images')\n",
    "orig_train_mask_dir = os.path.join(original_dataset_path, 'train/labels')\n",
    "orig_valid_img_dir  = os.path.join(original_dataset_path, 'validation/images')\n",
    "orig_valid_mask_dir = os.path.join(original_dataset_path, 'validation/labels')\n",
    "orig_test_img_dir   = os.path.join(original_dataset_path, 'test/images')\n",
    "orig_test_mask_dir  = os.path.join(original_dataset_path, 'test/labels')\n",
    "\n",
    "\n",
    "output_dirs = {\n",
    "    'train_images': os.path.join(output_base, 'images/train'),\n",
    "    'train_labels': os.path.join(output_base, 'labels/train'),\n",
    "    'valid_images': os.path.join(output_base, 'images/valid'),\n",
    "    'valid_labels': os.path.join(output_base, 'labels/valid'),\n",
    "    'test_images':  os.path.join(output_base, 'images/test'),\n",
    "    'test_labels':  os.path.join(output_base, 'labels/test'),\n",
    "}\n",
    "\n",
    "transforms = A.Compose([\n",
    "    A.Resize(*target_size, interpolation=cv2.INTER_NEAREST), #all augmented images were kept at $512 \\times 512$ resolution\n",
    "    A.HorizontalFlip(p=0.5), #random transformations including horizontal and vertical flips\n",
    "    A.VerticalFlip(p=0.5),   #random transformations including horizontal and vertical flips\n",
    "    A.RandomRotate90(p=0.5), #random rotations in multiples of 90°\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.7, border_mode=cv2.BORDER_REFLECT),\n",
    "    #translations, scaling, and small rotations limited to 10\\%, 10\\%, and 30\\% respectively\n",
    "    #A reflective padding strategy was used to preserve border continuity\n",
    "    A.RandomBrightnessContrast(p=0.5), #brightness and contrast adjustments ($p=0.5$)\n",
    "    A.ElasticTransform(p=0.2), #elastic deformations ($p=0.2$)\n",
    "    A.GaussianBlur(p=0.3), #Gaussian blur ($p=0.3$)\n",
    "    A.GridDistortion(p=0.2), #grid distortions ($p=0.2$)\n",
    "])\n",
    "\n",
    "augment_dataset(N, num_to_valid, num_to_test,\n",
    "                    orig_train_img_dir, orig_train_mask_dir,\n",
    "                    orig_valid_img_dir, orig_valid_mask_dir,\n",
    "                    orig_test_img_dir, orig_test_mask_dir,\n",
    "                    output_base,\n",
    "                    transforms,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fec6332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch5070",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
