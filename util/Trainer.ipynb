{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12db7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from util import *\n",
    "import pandas as pd \n",
    "from datetime import timedelta\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import os\n",
    "from util import count_trainable_parameters, measure_inference_speed\n",
    "\n",
    "#pip install XlsxWriter\n",
    "#jupyter nbconvert --to script Trainer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe37cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, mode='max', delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "        if self.mode == 'min':\n",
    "            self.sign = 1\n",
    "        else:  # 'max'\n",
    "            self.sign = -1\n",
    "\n",
    "    def step(self, score):\n",
    "        score = self.sign * score  # transform max into min if necessary\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_segmentation_metrics(preds, targets, num_classes, eps=1e-6):\n",
    "    preds = preds.view(-1).cpu()\n",
    "    targets = targets.view(-1).cpu()\n",
    "\n",
    "    dice_total          = 0.0\n",
    "    miou_total          = 0.0\n",
    "    iou_valid_classes   = 0\n",
    "    precision_per_class = []\n",
    "    recall_per_class    = []\n",
    "    f1_per_class        = []\n",
    "\n",
    "    # If it is binary, we only evaluate class 1\n",
    "    classes_to_eval = [1] if num_classes == 1 else range(num_classes)\n",
    "\n",
    "    for cls in classes_to_eval:\n",
    "        pred_mask = (preds == cls)\n",
    "        target_mask = (targets == cls)\n",
    "\n",
    "        intersection = (pred_mask & target_mask).sum().float()\n",
    "        pred_sum = pred_mask.sum().float()\n",
    "        target_sum = target_mask.sum().float()\n",
    "        union = pred_sum + target_sum\n",
    "\n",
    "        # Dice\n",
    "        if union > 0:\n",
    "            dice = (2.0 * intersection + eps) / (union + eps)\n",
    "            dice_total += dice.item()\n",
    "\n",
    "        # Io u\n",
    "        union_iou = (pred_mask | target_mask).sum().float()\n",
    "        if union_iou > 0:\n",
    "            iou = (intersection + eps) / (union_iou + eps)\n",
    "            miou_total += iou.item()\n",
    "            iou_valid_classes += 1\n",
    "\n",
    "        # Precision, Recall\n",
    "        tp = intersection.item()\n",
    "        fp = (pred_mask & ~target_mask).sum().float().item()\n",
    "        fn = (~pred_mask & target_mask).sum().float().item()\n",
    "\n",
    "        if (tp + fp + fn) > 0:\n",
    "            precision = tp / (tp + fp + eps)\n",
    "            recall = tp / (tp + fn + eps)\n",
    "            f1 = (2 * precision * recall) / (precision + recall + eps)\n",
    "\n",
    "            precision_per_class.append(precision)\n",
    "            recall_per_class.append(recall)\n",
    "            f1_per_class.append(f1)\n",
    "\n",
    "    mean_dice = dice_total / len(classes_to_eval)\n",
    "    mean_iou = miou_total / iou_valid_classes if iou_valid_classes > 0 else 0.0\n",
    "    mean_precision = np.mean(precision_per_class) if precision_per_class else 0.0\n",
    "    mean_recall = np.mean(recall_per_class) if recall_per_class else 0.0\n",
    "    mean_f1 = np.mean(f1_per_class) if f1_per_class else 0.0\n",
    "    q = mean_iou * mean_dice\n",
    "\n",
    "    return mean_dice, mean_iou, mean_precision, mean_recall, mean_f1, q\n",
    "\n",
    "\n",
    "# It calculates image by image and then takes the average.\n",
    "def compute_iou(preds, masks, num_classes=1, eps=1e-6):\n",
    "    iou_per_class = [ [] for _ in range(num_classes) ]  # list of lists\n",
    "\n",
    "    batch_size = preds.size(0)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        pred = preds[i]\n",
    "        mask = masks[i]\n",
    "\n",
    "        for cls in range(num_classes):\n",
    "            pred_cls = (pred == cls).float()\n",
    "            mask_cls = (mask == cls).float()\n",
    "\n",
    "            if mask_cls.sum() == 0:\n",
    "                continue  # does not evaluate missing class in ground truth\n",
    "\n",
    "            intersection = (pred_cls * mask_cls).sum()\n",
    "            union = ((pred_cls + mask_cls) > 0).float().sum()\n",
    "            iou = (intersection + eps) / (union + eps)\n",
    "            iou_per_class[cls].append(iou)\n",
    "\n",
    "    # average per class\n",
    "    class_ious = [\n",
    "        torch.stack(iou_list).mean()\n",
    "        for iou_list in iou_per_class\n",
    "        if len(iou_list) > 0\n",
    "    ]\n",
    "\n",
    "    if not class_ious:\n",
    "        return 0.0\n",
    "\n",
    "    return torch.stack(class_ious).mean().item()\n",
    "\n",
    "\n",
    "\n",
    "#LOSS FUNCTION 1 CLASSE\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # ECB (with logits)\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "\n",
    "        # Sigmoid to convert logits → probabilities\n",
    "        probs = torch.sigmoid(inputs)\n",
    "\n",
    "        # Flatten for Dice calculation\n",
    "        probs = probs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (probs * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (probs.sum() + targets.sum() + self.smooth)\n",
    "        dice_loss = 1 - dice\n",
    "\n",
    "        # Thoughtful combination\n",
    "        loss = self.bce_weight * bce_loss + (1 - self.bce_weight) * dice_loss\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e570e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    model         = None\n",
    "    criterion     = None\n",
    "    optimizer     = None\n",
    "    scheduler     = None\n",
    "    learning_rate = None\n",
    "    \n",
    "    #This class only trains segmentation with 1 class\n",
    "    #If more is needed, use SemanticTrainer\n",
    "    num_classes   = 2\n",
    "\n",
    "    def __init__(self, model_filename=None, model_dir=None, info={}, save_xlsx=False, load_best=True, device=None, rewrite_model=False, \n",
    "                 loss_function='BCEDiceLoss'):\n",
    "\n",
    "        if save_xlsx:\n",
    "            if model_filename is None:\n",
    "                raise Exception(\"model_filename is mandatory when with save_xlsx == True\")\n",
    "        self.save_xlsx = save_xlsx\n",
    "        self.load_best = load_best\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "        #saves the model name and directory\n",
    "        self.model_filename = model_filename\n",
    "        if model_dir is None:\n",
    "            model_dir = model_filename\n",
    "        self.model_dir = model_dir\n",
    "\n",
    "        #if at least the model name is passed\n",
    "        if self.model_filename is not None:\n",
    "            self.model_file_dir = self.model_dir + \"/\" + self.model_filename\n",
    "            self.hist_name = self.model_file_dir.replace('.pth', '.xlsx')\n",
    "            self.best_path           = self.model_file_dir.replace('.pth', '-best.pth')\n",
    "            self.last_path           = self.model_file_dir.replace('.pth', '-last.pth')\n",
    "        else:\n",
    "            self.model_file_dir = None\n",
    "\n",
    "        if rewrite_model and self.model_file_dir is not None:\n",
    "            if os.path.exists(self.hist_name):\n",
    "                os.remove(self.hist_name)\n",
    "            if os.path.exists(self.model_file_dir):\n",
    "                os.remove(self.model_file_dir)\n",
    "            if os.path.exists(self.best_path):\n",
    "                os.remove(self.best_path)\n",
    "            if os.path.exists(self.last_path):\n",
    "                os.remove(self.last_path)\n",
    "\n",
    "        #extra information to be saved in xlsx\n",
    "        self.info = info\n",
    "        #index of the sample image that will be used\n",
    "        #to save output during training\n",
    "        self.sample_img_fixed_index = 0\n",
    "        #Makes some initializations\n",
    "        self.create_criterion()\n",
    "\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        print(\"Device:\",self.device)\n",
    "\n",
    "    \n",
    "\n",
    "    def create_criterion(self):\n",
    "        self.info['loss_function'] = self.loss_function\n",
    "        if self.loss_function == 'BCEWithLogitsLoss':\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "        elif self.loss_function == 'BCEDiceLoss':\n",
    "            self.criterion = BCEDiceLoss(bce_weight=0.5)\n",
    "        #elif self.loss_function == 'BCEDiceLossMulticlass': #Not yet available here\n",
    "        #    self.criterion = BCEDiceLossMulticlass(bce_weight=0.5)\n",
    "        else:\n",
    "            raise ValueError(f'Loss function {self.loss_function} not found.')\n",
    "        print(\"Loss function:\", self.loss_function)\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    def create_scheduler(self, patience=10, factor=0.5, mode='max'):\n",
    "        self.info['scheduler'] = \"ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.5, verbose=True)\"\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, \n",
    "                                      mode=mode, \n",
    "                                      patience=patience, \n",
    "                                      factor=factor)\n",
    "        \n",
    "        \n",
    "\n",
    "    def create_optimizer(self):\n",
    "        self.info['optimizer'] = f\"optim.Adam(self.model.parameters(), lr={self.learning_rate})\"\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def train_loop(self, images, masks, epoch):\n",
    "        outputs     = self.get_model_output(images)\n",
    "\n",
    "        outputs_s   = outputs.squeeze(1)\n",
    "        masks_s     = masks.squeeze(1).float()\n",
    "\n",
    "        loss    = self.criterion(outputs_s, masks_s)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        train_loss = loss.item() * images.size(0)\n",
    "\n",
    "        return train_loss\n",
    "    \n",
    "\n",
    "\n",
    "    def update_history(self, history, train_loss=None, loss=None, dice=None, miou=None,\n",
    "                   iou=None, precision=None, recall=None, f1=None, q=None, \n",
    "                   elapsed_time=None, images_per_sec=None, started=None):\n",
    "        if train_loss is not None:\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "        if loss is not None:\n",
    "            history[\"loss\"].append(loss)\n",
    "        if dice is not None:\n",
    "            history[\"dice\"].append(dice)\n",
    "        if miou is not None:\n",
    "            history[\"miou\"].append(miou)\n",
    "        if f1 is not None:\n",
    "            history[\"f1\"].append(f1)\n",
    "        if iou is not None:\n",
    "            history[\"iou\"].append(iou)\n",
    "        if precision is not None:\n",
    "            history[\"precision\"].append(precision)\n",
    "        if recall is not None:\n",
    "            history[\"recall\"].append(recall)\n",
    "        if q is not None:\n",
    "            history[\"q\"].append(q)\n",
    "        if elapsed_time is not None:\n",
    "            history[\"elapsed_time\"].append(elapsed_time)\n",
    "        if images_per_sec is not None:\n",
    "            history[\"images_per_sec\"].append(images_per_sec)\n",
    "        if started is not None:\n",
    "            history[\"started\"].append(started)\n",
    "\n",
    "\n",
    "    \n",
    "    def print_last_history_stats(self):\n",
    "            def format_line(title, epoch_idx):\n",
    "                epoch = epoch_idx + 1\n",
    "                values = {k: self.val_history[k][epoch_idx] for k in self.val_history}\n",
    "                lr = self.val_history.get(\"lr\", [None] * len(self.val_history[\"loss\"]))[epoch_idx]\n",
    "                gpu_fps = values.get(\"GPU_FPS\", None)\n",
    "                cpu_fps = values.get(\"CPU_FPS\", None)\n",
    "                line = (\n",
    "                    f\"{title}:\\n\"\n",
    "                    f\" Epoch [{epoch}]\"\n",
    "                    f\" - Loss: {values.get('train_loss', float('nan')):.4f}\"\n",
    "                    f\" Val Loss: {values.get('loss', float('nan')):.4f}\"\n",
    "                    f\" Dice: {values.get('dice', float('nan')):.4f}\"\n",
    "                    f\" mIoU: {values.get('miou', float('nan')):.4f}\"\n",
    "                    f\" F1-score: {values.get('f1', float('nan')):.4f}\"\n",
    "                    f\" IoU: {values.get('iou', float('nan')):.4f}\"\n",
    "                    f\" Precision: {values.get('precision', float('nan')):.4f}\"\n",
    "                    f\" Recall: {values.get('recall', float('nan')):.4f}\"\n",
    "                    f\" Q: {values.get('q', float('nan')):.4f}\"\n",
    "                    f\" Tempo total: {values.get('elapsed_time', 'nan')}\"\n",
    "                )\n",
    "                if lr is not None:\n",
    "                    line += f\" LR:{lr:.6f}\"\n",
    "                if gpu_fps is not None:\n",
    "                    line += f\" GPU_FPS: {gpu_fps:.2f}\"\n",
    "                if cpu_fps is not None:\n",
    "                    line += f\" CPU_FPS: {cpu_fps:.2f}\"\n",
    "                return line\n",
    "\n",
    "            # best time (highest Dice)\n",
    "            best_epoch = int(max(range(len(self.val_history[\"dice\"])), key=lambda i: self.val_history[\"dice\"][i]))\n",
    "            print(format_line(\"Best model\", best_epoch))\n",
    "\n",
    "            # last season\n",
    "            last_epoch = len(self.val_history[\"dice\"]) - 1\n",
    "            print(format_line(\"Latest model\", last_epoch))\n",
    "\n",
    "\n",
    "    def do_save_xlsx(self):\n",
    "\n",
    "        avg_speed = sum(self.val_history['images_per_sec']) / len(self.val_history['images_per_sec'])\n",
    "        self.info['training_speed_img_per_sec'] = round(avg_speed, 2)\n",
    "\n",
    "        df_val_history = pd.DataFrame(self.val_history)\n",
    "        df_val_history.insert(0, 'epoch', range(1, len(df_val_history)+1))\n",
    "        df_val_history['epoch'] = df_val_history['epoch'].astype(str)\n",
    "\n",
    "\n",
    "        df_test_history = pd.DataFrame(self.test_history)\n",
    "        df_test_history.insert(0, 'epoch', range(1, len(df_test_history)+1))\n",
    "        df_test_history['epoch'] = df_test_history['epoch'].astype(str)\n",
    "\n",
    "\n",
    "        df_info = pd.DataFrame(self.info, index=[0])\n",
    "        with pd.ExcelWriter(self.hist_name, engine='xlsxwriter') as writer:\n",
    "            df_val_history.to_excel(writer, sheet_name='val_history', index=False, float_format=\"%.4f\")\n",
    "            df_test_history.to_excel(writer, sheet_name='test_history', index=False, float_format=\"%.4f\")\n",
    "            df_info.to_excel(writer, sheet_name='model_info', index=False, float_format=\"%.4f\")\n",
    "\n",
    "            workbook  = writer.book\n",
    "            worksheet = writer.sheets['val_history']\n",
    "\n",
    "            chart = workbook.add_chart({'type': 'line'})\n",
    "\n",
    "            # The 'epoch' column is now in column 0\n",
    "            # Assuming 'val_dice' is in column 5 and 'val_IoU' in 6 (or adjust this dynamically)\n",
    "            col_dice = df_val_history.columns.get_loc('dice')\n",
    "            col_iou  = df_val_history.columns.get_loc('miou')\n",
    "\n",
    "            chart.add_series({\n",
    "                'name':       'dice',\n",
    "                'categories': ['val_history', 1, 0, len(df_val_history), 0],  # column 0 = epoch\n",
    "                'values':     ['val_history', 1, col_dice, len(df_val_history), col_dice],\n",
    "            })\n",
    "            chart.add_series({\n",
    "                'name':       'mIoU',\n",
    "                'categories': ['val_history', 1, 0, len(df_val_history), 0],\n",
    "                'values':     ['val_history', 1, col_iou, len(df_val_history), col_iou],\n",
    "            })\n",
    "\n",
    "            chart.set_title({'name': 'Training'})\n",
    "\n",
    "            chart.set_x_axis({\n",
    "                'name': 'Epoch',\n",
    "                'interval_unit': 10,\n",
    "                'num_font': {'rotation': -45},\n",
    "            })\n",
    "            chart.set_y_axis({'name': 'Value'})\n",
    "\n",
    "            worksheet.insert_chart('K2', chart)\n",
    "\n",
    "    \n",
    "    \n",
    "    def load_xlsx_history(self):\n",
    "        # Read all sheets in the file\n",
    "        xls = pd.read_excel(self.hist_name, sheet_name=None)\n",
    "\n",
    "        # Retrieves the history DataFrame and converts it to a dictionary list\n",
    "        df_val_history   = xls['val_history']\n",
    "        last_epoch   = int(df_val_history['epoch'].iloc[-1])\n",
    "        self.val_history = df_val_history.drop(columns=['epoch']).to_dict(orient='list')\n",
    "\n",
    "\n",
    "        df_test_history   = xls['test_history']\n",
    "        self.test_history = df_test_history.drop(columns=['epoch']).to_dict(orient='list')\n",
    "\n",
    "        # Accumulated time\n",
    "        elapsed_str      = df_val_history['elapsed_time'].iloc[-1]\n",
    "        h, m, s          = map(int, elapsed_str.split(':'))\n",
    "        accumulated_time = timedelta(hours=h, minutes=m, seconds=s).total_seconds()\n",
    "        start_time       = time.time() - accumulated_time  # Adjusts to maintain accumulated count\n",
    "\n",
    "        # Retrieves model information DataFrame and converts to dictionary\n",
    "        df_info = xls['model_info']\n",
    "        self.info = df_info.iloc[0].to_dict()\n",
    "        return last_epoch, start_time\n",
    "\n",
    "    def load_model(self, model_file_dir, model=None, load_xlsx=True, load_scheduler=False):\n",
    "        #if the model is passed\n",
    "        if model is not None:\n",
    "            #self.model receives the new model\n",
    "            self.model = model\n",
    "        #if the model to be loaded has not been passed\n",
    "        if self.model is None:\n",
    "            raise Exception(\"You need to pass the model object in the 'model' parameter\")\n",
    "        \n",
    "        if self.optimizer is None:\n",
    "            self.create_optimizer()\n",
    "        if self.scheduler is None:\n",
    "            self.create_scheduler()\n",
    "        \n",
    "        #loads the model from the .pth file\n",
    "        checkpoint = torch.load(model_file_dir, weights_only=False)\n",
    "        #retrieves the states of the file\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if load_scheduler:\n",
    "            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_score  = checkpoint['best_acc']\n",
    "        epoch       = checkpoint['epoch'] + 1\n",
    "        self.model.to(self.get_device())\n",
    "        print(f\"Loaded model: {model_file_dir}\")\n",
    "        if load_xlsx:\n",
    "            start_epoch, start_time = self.load_xlsx_history()\n",
    "            return best_score, epoch, start_epoch, start_time\n",
    "        return best_score, epoch\n",
    "    \n",
    "    def save_model(self, path, epoch, best_score):\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "                'best_acc': best_score\n",
    "                }, path)\n",
    "    \n",
    "    def get_device(self):\n",
    "        return self.device\n",
    "\n",
    "\n",
    "    def get_model_output(self,images):\n",
    "        return self.model(images)\n",
    "        \n",
    "\n",
    "    def val_loop(self, images, masks):\n",
    "        outputs     = self.get_model_output(images)\n",
    "        loss        = self.criterion(outputs, masks)\n",
    "        val_loss    = loss.item() * images.size(0)\n",
    "\n",
    "        #make the threshold\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        preds = (preds > 0.5).long()\n",
    "        masks = masks.long()\n",
    "\n",
    "        #compute the metrics\n",
    "        dice, mIoU, precision, recall, f1, q = compute_segmentation_metrics(preds, masks, num_classes=self.num_classes)\n",
    "        IoU = compute_iou(preds, masks, num_classes=self.num_classes)\n",
    "        val_dice      = dice      * images.size(0)\n",
    "        val_mIoU      = mIoU      * images.size(0)\n",
    "        val_IoU       = IoU       * images.size(0)\n",
    "        val_precision = precision * images.size(0)\n",
    "        val_recall    = recall    * images.size(0)\n",
    "        val_f1        = f1        * images.size(0)\n",
    "        val_q         = q         * images.size(0)\n",
    "        return val_loss, val_dice, val_mIoU, val_IoU, val_precision, val_recall, val_f1, val_q\n",
    "\n",
    "    def evaluate_model(self, data_loader, print_stats=False, model=None):\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "        self.model.eval()\n",
    "        device      = self.get_device()\n",
    "        loss        = 0.0\n",
    "        dice        = 0.0\n",
    "        mIoU        = 0.0\n",
    "        IoU         = 0.0\n",
    "        precision   = 0.0\n",
    "        recall      = 0.0\n",
    "        f1          = 0.0\n",
    "        q           = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in data_loader:\n",
    "                images = images.to(device)\n",
    "                masks  = masks.to(device)\n",
    "                iloss, idice, imIoU, iIoU, iprecision, irecall, if1, iq = self.val_loop(images, masks)\n",
    "                \n",
    "                loss      += iloss\n",
    "                dice      += idice\n",
    "                mIoU      += imIoU\n",
    "                IoU       += iIoU\n",
    "                precision += iprecision\n",
    "                recall    += irecall\n",
    "                f1        += if1\n",
    "                q         += iq\n",
    "\n",
    "        avg_loss        = loss / len(data_loader.dataset)\n",
    "        avg_dice        = dice / len(data_loader.dataset)\n",
    "        avg_mIoU        = mIoU / len(data_loader.dataset)\n",
    "        avg_IoU         = IoU  / len(data_loader.dataset)\n",
    "        avg_precision   = precision   / len(data_loader.dataset)\n",
    "        avg_recall      = recall   / len(data_loader.dataset)\n",
    "        avg_f1          = f1    / len(data_loader.dataset)\n",
    "        avg_q           = q    / len(data_loader.dataset)\n",
    "\n",
    "        if print_stats:\n",
    "            stats = (f\"Loss: {avg_loss:.4f} \" \n",
    "                    f\"Dice: {avg_dice:.4f} mIoU: {avg_mIoU:.4f} F1: {avg_f1:.4f}  IoU: {avg_IoU:.4f} \" \n",
    "                    f\"Prec: {avg_precision:.4f} \" \n",
    "                    f\"Recall: {avg_recall:.4f} Q: {avg_q:.4f} \")\n",
    "            print(stats)\n",
    "\n",
    "        return avg_loss, avg_dice, avg_mIoU, avg_IoU, avg_precision, avg_recall, avg_f1, avg_q\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, model, \n",
    "                    train_loader, \n",
    "                    val_loader,\n",
    "                    test_loader, \n",
    "                    num_epochs=50, \n",
    "                    #saves the model every\n",
    "                    save_every=None,\n",
    "                    #prints the tempo every\n",
    "                    print_every=None,\n",
    "                    #continue training where you left off\n",
    "                    continue_from_last=False,\n",
    "                    #verbose==1 prints the training on the same line\n",
    "                    verbose=3,\n",
    "                    learning_rate=1e-4,\n",
    "                    # scheduler patience=decreases IR after 10 epochs without improvement in acc\n",
    "                    scheduler_patience=10,\n",
    "                    # early_stop_patience=ends training after 20 epochs if acc improves\n",
    "                    early_stop_patience=20,\n",
    "                    measure_cpu_speed=True\n",
    "                    ):\n",
    "\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        device = self.get_device()\n",
    "\n",
    "        self.learning_rate  = learning_rate\n",
    "        self.model          = model\n",
    "        start_epoch         = 0\n",
    "        best_score          = -1.0\n",
    "        best_stats          = \"\"\n",
    "        start_time          = time.time()\n",
    "        started             = False\n",
    "        batch_size          = train_loader.batch_size\n",
    "\n",
    "        trainable_parameters = count_trainable_parameters(model)\n",
    "        print(\"trainable_parameters:\", trainable_parameters)\n",
    "        self.info['dataset_name']         = train_loader.dataset.__module__\n",
    "        self.info['dataset_batch_size']   = batch_size\n",
    "        self.info['trainable_parameters'] = trainable_parameters\n",
    "        images, labels = next(iter(train_loader))\n",
    "        self.info['dataset_resolution']   = f\"{images.shape[2]} x {images.shape[3]}\"\n",
    "        \n",
    "\n",
    "        self.val_history = {\n",
    "            \"train_loss\":     [],\n",
    "            \"loss\":           [],\n",
    "            \"dice\":           [],\n",
    "            \"miou\":           [],\n",
    "            \"f1\":             [],\n",
    "            \"iou\":            [],\n",
    "            \"precision\":      [],\n",
    "            \"recall\":         [],\n",
    "            \"q\":              [],\n",
    "            \"elapsed_time\":   [],\n",
    "            \"images_per_sec\": [],\n",
    "            \"started\":        [],\n",
    "        }\n",
    "        self.test_history = {k: [] for k in self.val_history}\n",
    "        \n",
    "\n",
    "        #prints everything on the same line\n",
    "        tqdm_disable = print_every!=None\n",
    "        print_end    = '\\r\\n'\n",
    "        if verbose == 1:\n",
    "            print_end    = '\\r'\n",
    "            tqdm_disable = True\n",
    "\n",
    "\n",
    "        \n",
    "        #if the model name was passed\n",
    "        if self.model_filename is not None:\n",
    "            #create directories\n",
    "            os.makedirs(self.model_dir, exist_ok=True)\n",
    "\n",
    "            #First, it checks whether the final, trained model already exists\n",
    "            if os.path.exists(self.model_file_dir):\n",
    "                if self.load_best:\n",
    "                    #if it already exists, load and return\n",
    "                    print(\"Trained model already exists (Loading better version).\")\n",
    "                    self.load_model(self.best_path)\n",
    "                else:\n",
    "                    #if it already exists, load and return\n",
    "                    print(\"Trained model already exists (Loading latest version).\")\n",
    "                    self.load_model(self.model_file_dir)\n",
    "                self.print_last_history_stats()\n",
    "                return model\n",
    "            #if it does not exist and is a continuation of the training\n",
    "            elif continue_from_last == True:\n",
    "                #continues from -last\n",
    "                if os.path.exists(self.last_path):\n",
    "                    _, _, start_epoch, start_time = self.load_model(self.last_path)\n",
    "                    print(f\"Continuing from the saved model: {self.last_path}\")\n",
    "                    print(f\"start_epoch: {start_epoch}, start_time: {start_time}\")\n",
    "                    if start_epoch >= num_epochs:\n",
    "                        self.print_last_history_stats()\n",
    "                        return self.model\n",
    "            \n",
    "\n",
    "\n",
    "        model.to(device)\n",
    "        self.create_optimizer()\n",
    "        self.create_scheduler(patience=scheduler_patience)\n",
    "        early_stopper = EarlyStopping(patience=early_stop_patience, mode='max')\n",
    "    \n",
    "        \n",
    "\n",
    "        ## Training\n",
    "        epoch = start_epoch\n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            \n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for images, masks in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", disable=tqdm_disable):\n",
    "                images = images.to(device)\n",
    "                masks  = masks.to(device)\n",
    "                ## training loop\n",
    "                train_loss += self.train_loop(images, masks, epoch)\n",
    "\n",
    "            avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "            \n",
    "\n",
    "            ## Validation\n",
    "            avg_val_loss, avg_val_dice, avg_val_mIoU, avg_val_IoU, avg_val_precision, avg_val_recall, avg_val_f1, avg_val_q = self.evaluate_model(val_loader)\n",
    "\n",
    "\n",
    "            ##Test\n",
    "            avg_test_loss, avg_test_dice, avg_test_mIoU, avg_test_IoU, avg_test_precision, avg_test_recall, avg_test_f1, avg_test_q = self.evaluate_model(test_loader)\n",
    "\n",
    "            elapsed     = time.time() - start_time\n",
    "            elapsed_str = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed))\n",
    "            current_lr  = self.optimizer.param_groups[0]['lr']\n",
    "            stats = (f\"Epoch [{epoch+1}/{num_epochs}] - \" \n",
    "                    f\"Loss: {avg_train_loss:.4f} Val Loss: {avg_val_loss:.4f} \" \n",
    "                    f\"Dice: {avg_val_dice:.4f} mIoU: {avg_val_mIoU:.4f} F1: {avg_val_f1:.4f} IoU: {avg_val_IoU:.4f} \" \n",
    "                    f\"Prec: {avg_val_precision:.4f} \" \n",
    "                    f\"Recall: {avg_val_recall:.4f} Q: {avg_val_q:.4f} \" \n",
    "                    f\"Time: {elapsed_str} LR:{current_lr:.6f}\")\n",
    "\n",
    "\n",
    "            if print_every is None:\n",
    "                print(stats,end=print_end)\n",
    "            else:\n",
    "                if (epoch+1) % print_every == 0:\n",
    "                    print(stats,end=print_end)\n",
    "            \n",
    "\n",
    "            images_per_sec = (len(train_loader) * batch_size) / elapsed\n",
    "            \n",
    "            ## Saves the evolution of the network\n",
    "            self.update_history(\n",
    "                self.val_history,\n",
    "                train_loss=avg_train_loss,\n",
    "                loss=avg_val_loss,\n",
    "                dice=avg_val_dice,\n",
    "                miou=avg_val_mIoU,\n",
    "                iou=avg_val_IoU,\n",
    "                precision=avg_val_precision,\n",
    "                recall=avg_val_recall,\n",
    "                f1=avg_val_f1,\n",
    "                q=avg_val_q,\n",
    "                elapsed_time=elapsed_str,\n",
    "                images_per_sec=images_per_sec,\n",
    "                started=('started' if not started else '')\n",
    "            )\n",
    "            self.update_history(\n",
    "                self.test_history,\n",
    "                train_loss=avg_train_loss,\n",
    "                loss=avg_test_loss,\n",
    "                dice=avg_test_dice,\n",
    "                miou=avg_test_mIoU,\n",
    "                iou=avg_test_IoU,\n",
    "                precision=avg_test_precision,\n",
    "                recall=avg_test_recall,\n",
    "                f1=avg_test_f1,\n",
    "                q=avg_test_q,\n",
    "                elapsed_time=elapsed_str,\n",
    "                images_per_sec=images_per_sec,\n",
    "                started=('started' if not started else '')\n",
    "            )\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            started = True\n",
    "\n",
    "\n",
    "            # The avg_val_dice will be observed for the scheduler and early_stopper\n",
    "\n",
    "            # reduces the learning rate if the score does not improve\n",
    "            self.scheduler.step(avg_val_dice)\n",
    "\n",
    "            # for training if you don't improve in X times\n",
    "            early_stopper.step(avg_val_dice)\n",
    "            if early_stopper.early_stop:\n",
    "                print(f\"Stopping at epoch {epoch+1} by early stopping.\")\n",
    "                break\n",
    "\n",
    "            ## Save the best model so far\n",
    "            if avg_val_dice > best_score:\n",
    "                best_score = avg_val_dice\n",
    "                \n",
    "                if self.model_file_dir is not None:\n",
    "                    #save the model at the best time\n",
    "                    self.save_model(self.best_path, epoch, best_score)\n",
    "                    current_lr  = self.optimizer.param_groups[0]['lr']\n",
    "                    best_stats = (f\"Epoch [{epoch+1}/{num_epochs}] - \" \n",
    "                                f\"Loss: {avg_train_loss:.4f} Val Loss: {avg_val_loss:.4f} \" \n",
    "                                f\"Dice: {avg_val_dice:.4f} mIoU: {avg_val_mIoU:.4f} F1: {avg_val_f1:.4f} IoU: {avg_val_IoU:.4f} \" \n",
    "                                f\"Prec: {avg_val_precision:.4f} \" \n",
    "                                f\"Recall: {avg_val_recall:.4f} Q: {avg_val_q:.4f} \" \n",
    "                                f\"Time: {elapsed_str} LR:{current_lr:.6f}\")\n",
    "                    if print_every is None and verbose > 1:\n",
    "                        print(\"✔ Best model saved:\", best_stats, end=print_end)\n",
    "                    #save excel to the current moment\n",
    "                    if self.save_xlsx:\n",
    "                        self.do_save_xlsx()\n",
    "            \n",
    "                \n",
    "\n",
    "            #Saves the network every\n",
    "            if save_every is not None and (epoch + 1) % save_every == 0:\n",
    "                last_model_file_dir = self.model_file_dir.replace('.pth','-last.pth')\n",
    "                self.save_model(last_model_file_dir, epoch, best_score)\n",
    "                self.do_save_xlsx()\n",
    "                if verbose > 1:\n",
    "                    print(\"Saved last as\", last_model_file_dir, end=print_end)\n",
    "\n",
    "\n",
    "        \n",
    "        last_stats = (f\"Epoch [{epoch+1}/{num_epochs}] - \" \n",
    "                    f\"Loss: {avg_train_loss:.4f} Val Loss: {avg_val_loss:.4f} \" \n",
    "                    f\"Dice: {avg_val_dice:.4f} mIoU: {avg_val_mIoU:.4f} F1: {avg_val_f1:.4f} IoU: {avg_val_IoU:.4f} \" \n",
    "                    f\"Prec: {avg_val_precision:.4f} \" \n",
    "                    f\"Recall: {avg_val_recall:.4f} Q: {avg_val_q:.4f} \" \n",
    "                    f\"Time: {elapsed_str} LR:{current_lr:.6f}\")\n",
    "        \n",
    "\n",
    "\n",
    "        #calculates the FPS of the model\n",
    "        self.info['GPU_FPS'], self.info['GPU_time_per_image'], self.info['CPU_FPS'], self.info['CPU_time_per_image'] = measure_inference_speed(self.model, \n",
    "                                                                                                                                               val_loader, \n",
    "                                                                                                                                               measure_cpu_speed=measure_cpu_speed)\n",
    "          \n",
    "        print(\"\")\n",
    "        if best_stats:\n",
    "            print(\"Best model:\\r\\n\", best_stats)\n",
    "        print(\"Latest model:\\r\\n\", last_stats + '\\r\\n GPU_FPS:',self.info['GPU_FPS'], ' CPU_FPS:',self.info['CPU_FPS'])\n",
    "\n",
    "\n",
    "        if self.model_file_dir is not None:\n",
    "            self.save_model(self.model_file_dir, epoch, best_score)\n",
    "            print(\"Saved as\", self.model_file_dir)\n",
    "\n",
    "        \n",
    "        if self.save_xlsx:\n",
    "            # Write the excel file with history\n",
    "            self.do_save_xlsx()\n",
    "\n",
    "        #beep win\n",
    "        #os.system('powershell.exe -Command \"[console]::beep(600,200); [console]::beep(600,200);\"')\n",
    "        #linux\n",
    "        os.system('play -nq -t alsa synth 0.2 sine 600; play -nq -t alsa synth 0.2 sine 600')\n",
    "        return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e18643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_masks_for_ce_loss(masks, num_classes=3, ignore_index=255):\n",
    "    \"\"\"\n",
    "    Checks a mask for invalid values ​​before CrossEntropyLoss.\n",
    "    \n",
    "    masks: tensor [B,H,W] ou [B,1,H,W]\n",
    "    \"\"\"\n",
    "    if masks.ndim == 4:\n",
    "        masks = masks.squeeze(1)  # [b,h,w]\n",
    "\n",
    "    invalid_mask = (masks < 0) | ((masks >= num_classes) & (masks != ignore_index))\n",
    "    has_invalid = invalid_mask.any()\n",
    "\n",
    "    if has_invalid:\n",
    "        print(\"Invalid values ​​found in masks!\")\n",
    "        for b in range(masks.size(0)):\n",
    "            unique_vals = torch.unique(masks[b])\n",
    "            if ((unique_vals >= num_classes) & (unique_vals != ignore_index)).any() or (unique_vals < 0).any():\n",
    "                print(f\"Batch {b}: unique values -> {unique_vals.tolist()}\")\n",
    "    else:\n",
    "        print(\"All masks valid for CrossEntropyLoss.\")\n",
    "\n",
    "\n",
    "class MulticlassTrainer(Trainer):\n",
    "\n",
    "    def __init__(self, num_classes, model_filename=None, model_dir=None, info={}, save_xlsx=False, loss_function='CrossEntropyLoss'):\n",
    "        #Correct the loss_function if necessary\n",
    "        if loss_function == 'BCEWithLogitsLoss':\n",
    "            loss_function = 'CrossEntropyLoss'\n",
    "\n",
    "        super(MulticlassTrainer, self).__init__(model_filename=model_filename, model_dir=model_dir, info=info, save_xlsx=save_xlsx, loss_function=loss_function)\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        \n",
    "    def create_criterion(self):\n",
    "        \n",
    "        if self.loss_function == 'CrossEntropyLoss':\n",
    "            self.info['loss_function'] = 'CrossEntropyLoss'\n",
    "            self.criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "        else:\n",
    "            raise ValueError(f'Loss function {self.loss_function} not found.') \n",
    "\n",
    "        \n",
    "    \n",
    "    def train_loop(self, images, masks, epoch):\n",
    "        outputs     = self.get_model_output(images)\n",
    "\n",
    "        masks_s     = masks.long().squeeze(1)\n",
    "\n",
    "        loss    = self.criterion(outputs, masks_s)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        train_loss = loss.item() * images.size(0)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "\n",
    "    def val_loop(self, images, masks):\n",
    "        outputs     = self.get_model_output(images)\n",
    "\n",
    "        masks_s     = masks.long().squeeze(1)\n",
    "\n",
    "        \n",
    "        try:\n",
    "            loss        = self.criterion(outputs, masks_s)\n",
    "            val_loss    = loss.item() * images.size(0)\n",
    "        except Exception as e:\n",
    "            check_masks_for_ce_loss(masks_s, num_classes=self.num_classes, ignore_index=255)\n",
    "            raise\n",
    "        \n",
    "        preds       = torch.argmax(outputs, dim=1)\n",
    "        dice, mIoU, precision, recall, f1, q = compute_segmentation_metrics(preds, masks, self.num_classes)\n",
    "        IoU = compute_iou(preds, masks, num_classes=self.num_classes)\n",
    "\n",
    "        val_dice      = dice      * images.size(0)\n",
    "        val_mIoU      = mIoU      * images.size(0)\n",
    "        val_IoU       = IoU       * images.size(0)\n",
    "        val_precision = precision * images.size(0)\n",
    "        val_recall    = recall    * images.size(0)\n",
    "        val_f1        = f1        * images.size(0)\n",
    "        val_q         = q         * images.size(0)\n",
    "\n",
    "        return val_loss, val_dice, val_mIoU, val_IoU, val_precision, val_recall, val_f1, val_q\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch5070",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
